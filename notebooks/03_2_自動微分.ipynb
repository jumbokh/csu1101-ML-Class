{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "03_2_自動微分.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jumbokh/csu1101-ML-Class/blob/main/notebooks/03_2_%E8%87%AA%E5%8B%95%E5%BE%AE%E5%88%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjxY6dz4ub0p"
      },
      "source": [
        "## 自動微分(Automatic Differentiation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddxGRAMKub0v",
        "outputId": "bd316fc6-a7ff-4fe4-a010-02ea6cba0253"
      },
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf \n",
        "\n",
        "x = tf.Variable(3.0)         # 宣告 TensorFlow 變數(Variable)\n",
        "\n",
        "with tf.GradientTape() as g: # 自動微分\n",
        "    y = x * x                # y = x^2\n",
        "    \n",
        "dy_dx = g.gradient(y, x)     # 取得梯度， f'(x) = 2x, x=3 ==> 6\n",
        "\n",
        "print(dy_dx.numpy())         # 轉換為 NumPy array 格式"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1GwqYNxub0y",
        "outputId": "37f40f4f-f96e-4916-cc81-2a27aac9b190"
      },
      "source": [
        "import numpy as np \n",
        "import tensorflow as tf \n",
        "\n",
        "x = tf.constant(3.0)         # 宣告 TensorFlow 常數\n",
        "\n",
        "with tf.GradientTape() as g: # 自動微分\n",
        "    g.watch(x)               # 設定常數參與自動微分\n",
        "    y = x * x                # y = x^2\n",
        "    \n",
        "dy_dx = g.gradient(y, x)     # 取得梯度， f'(x) = 2x, x=3 ==> 6\n",
        "\n",
        "print(dy_dx.numpy())         # 轉換為 NumPy array 格式"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9encVmDub0y"
      },
      "source": [
        "## 二階導數計算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qONrYdeXub0z",
        "outputId": "43623a41-4cb9-4cda-bebe-d8f1735fa6ba"
      },
      "source": [
        "x = tf.constant(3.0)              # 宣告 TensorFlow 常數\n",
        "with tf.GradientTape() as g:      # 自動微分\n",
        "    g.watch(x)\n",
        "    with tf.GradientTape() as gg: # 自動微分\n",
        "        gg.watch(x)               # 設定常數參與自動微分\n",
        "        y = x * x                 # y = x^2\n",
        "        \n",
        "    dy_dx = gg.gradient(y, x)     # 一階導數\n",
        "d2y_dx2 = g.gradient(dy_dx, x)    # 二階導數\n",
        "\n",
        "print(f'一階導數={dy_dx.numpy()}, 二階導數={d2y_dx2.numpy()}') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "一階導數=6.0, 二階導數=2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuMNXLbTub00"
      },
      "source": [
        "## 多變數導數計算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKMHOqJcub00",
        "outputId": "ba5fee02-e8ad-4262-857c-a472b2586b9f"
      },
      "source": [
        "x = tf.Variable(3.0)          # 宣告 TensorFlow 常數\n",
        "with tf.GradientTape(persistent=True) as g:  # 自動微分\n",
        "    y = x * x                 # y = x^2\n",
        "    z = y * y                 # z = y^2\n",
        "    \n",
        "dz_dx = g.gradient(z, x)      # 4*x^3\n",
        "dy_dx = g.gradient(y, x)      # 2*x\n",
        "\n",
        "del g                         # 不用時可刪除 GradientTape 物件\n",
        "\n",
        "print(f'dy/dx={dy_dx.numpy()}, dz/dx={dz_dx.numpy()}') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dy/dx=6.0, dz/dx=108.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gisZ1YL3ub02"
      },
      "source": [
        "## PyTorch自動微分的語法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbH9kSk-ub02",
        "outputId": "3153b076-9719-45cc-f4b8-c6946706f579"
      },
      "source": [
        "import torch       # 載入套件\n",
        "\n",
        "x = torch.tensor(3.0, requires_grad=True)  # 設定 x 參與自動微分\n",
        "y=x*x              # y = x^2\n",
        "\n",
        "y.backward()       # 反向傳導\n",
        "\n",
        "print(x.grad)      # 取得梯度"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD5jfKEsub03"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}